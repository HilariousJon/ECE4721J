import argparse
import pickle
import numpy as np
import faiss
from loguru import logger


def query_recommendations(index_prefix: str, weighted_tracks: list, k: int = 20):
    logger.info("--- Starting Recommendation Query ---")

    # Load Pre-built Index and Mappings
    logger.info(f"Loading index and mappings from prefix: '{index_prefix}'...")
    index_file = f"{index_prefix}_index.ann"
    id_map_file = f"{index_prefix}_id_map.pkl"
    vector_map_file = f"{index_prefix}_vector_map.pkl"

    try:
        index = faiss.read_index(index_file)
        with open(id_map_file, "rb") as f:
            idx_to_track_id = pickle.load(f)
        with open(vector_map_file, "rb") as f:
            track_id_to_vector = pickle.load(f)
    except FileNotFoundError as e:
        logger.error(f"FATAL: Could not find necessary index file. Error: {e}")
        logger.error("Please ensure you have run 'build_ann_index.py' first.")
        return

    logger.success("Index and mappings loaded successfully.")

    # Create the Weighted "Taste Vector"
    logger.info("Creating weighted taste vector from input tracks...")
    taste_vector = np.zeros(index.d, dtype="float32")
    total_weight = 0.0

    input_track_ids = set()
    for track_info in weighted_tracks:
        try:
            track_id, weight = track_info.split(":")
            weight = float(weight)
            input_track_ids.add(track_id)

            if track_id in track_id_to_vector:
                logger.debug(f"Adding track '{track_id}' with weight {weight}")
                taste_vector += track_id_to_vector[track_id] * weight
                total_weight += weight
            else:
                logger.warning(
                    f"Track ID '{track_id}' not found in our dataset. Skipping."
                )
        except ValueError:
            logger.error(
                f"Invalid format for --track: '{track_info}'. Please use 'TRACK_ID:WEIGHT'."
            )
            return

    if total_weight == 0.0:
        logger.error("Could not create a taste vector. No valid input tracks found.")
        return

    taste_vector /= total_weight
    taste_vector_normalized = taste_vector / np.linalg.norm(taste_vector)
    logger.success("Taste vector created and normalized.")

    # Query the ANN Index
    logger.info(f"Querying index for {k} nearest neighbors...")
    query_vector_2d = np.array([taste_vector_normalized]).astype("float32")
    distances, indices = index.search(query_vector_2d, k + len(input_track_ids))

    # Process and Display Results
    logger.info("--- Recommendation Results ---")
    count = 0
    # For L2 normalized vectors, Cosine Similarity = 1 - (L2_distance^2 / 2)
    for i, dist in zip(indices[0], distances[0]):
        if count >= k:
            break

        recommended_track_id = idx_to_track_id[i]

        if recommended_track_id in input_track_ids:
            continue

        similarity_score = 1 - (dist**2 / 2)

        print(f"  - Rank {count + 1}:")
        print(f"    Track ID: {recommended_track_id}")
        print(f"    Similarity Score: {similarity_score:.4f}")
        count += 1

    if count == 0:
        logger.warning("No new recommendations found. Try different input songs.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Get song recommendations based on a weighted list of tracks."
    )
    parser.add_argument(
        "-idx",
        "--index",
        required=True,
        type=str,
        help="Prefix of the index files generated by the build script.",
    )
    parser.add_argument(
        "-t",
        "--track",
        required=True,
        action="append",
        help="Input track in 'TRACK_ID:WEIGHT' format. Can be specified multiple times.",
    )
    parser.add_argument(
        "-k", type=int, default=10, help="Number of recommendations to return."
    )
    args = parser.parse_args()

    query_recommendations(args.index, args.track, args.k)
